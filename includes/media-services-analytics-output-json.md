作业将生成一个 JSON 输出文件，其中包含有关检测到的和跟踪的面部的元数据。 元数据包括指示面部位置的坐标，以及指示正在跟踪该人员的面部 ID 编号。 在正面面部长时间于帧中消失或重叠的情况下，面部 ID 编号很容易重置，导致某些人员被分配多个 ID。

输出 JSON 包含以下属性：

| 元素 | 说明 |
| --- | --- |
| 版本 |这是指视频 API 的版本。 |
| index | （仅适用于 Azure 媒体编修器）定义当前事件的帧索引。 |
| 时间刻度 |视频每秒的“刻度”数。 |
| offset |这是时间戳的时间偏移量。 在版本 1.0 的视频 API 中，此属性始终为 0。 在我们将来支持的方案中，此值可能会更改。 |
| 帧速率 |视频的每秒帧数。 |
| 片段 |元数据划分成称为“片段”的不同段。 每个片段包含开始时间、持续时间、间隔数字和事件。 |
| start |第一个事件的开始时间（以“刻度”为单位）。 |
| duration |片段的长度（以“刻度”为单位）。 |
| interval |片段中每个事件条目的间隔（以“刻度”为单位）。 |
| 活动 |每个事件包含在该持续时间内检测到并跟踪的面部。 它是包含事件数组的数组。 外部数组代表一个时间间隔。 内部数组包含在该时间点发生的 0 个或多个事件。 空括号 [] 代表没有检测到人脸。 |
| id |正在跟踪的面部的 ID。 如果某个面部后来未被检测到，此编号可能会意外更改。 给定人员在整个视频中应该拥有相同的 ID，但由于检测算法的限制（例如受到阻挡等情况），我们无法保证这一点。 |
| x, y |规范化 0.0 到 1.0 比例中面部边框左上角的 X 和 Y 坐标。 <br/>-X 和 Y 坐标总是相对于横向方向，因此如果视频是纵向（或使用 iOS 时上下颠倒），便需要相应地变换坐标。 |
| 宽度、高度 |规范化 0.0 到 1.0 比例中面部边框的宽度和高度。 |
| facesDetected |位于 JSON 结果的末尾，汇总在生成视频期间算法所检测到的面部数。 由于 ID 可能在面部无法检测时（例如面部离开屏幕、转向别处）意外重置，此数字并不一定与视频中的实际面部数相同。 |

