---
title: 准备用于 ML Studio （经典）的数据-团队数据科学流程
description: 기계 학습에 효과적으로 사용될 수 있도록 준비하기 위해 데이터를 전처리하고 정리합니다.
services: machine-learning
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 01/10/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: caedcf313ab809e9607907545f26ca1b62bbeca7
ms.sourcegitcommit: f52ce6052c795035763dbba6de0b50ec17d7cd1d
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 01/24/2020
ms.locfileid: "76720038"
---
# <a name="tasks-to-prepare-data-for-enhanced-machine-learning"></a>확장된 기계 학습을 위한 데이터 준비 작업
预处理和清理数据是必须在将数据集用于模型定型之前执行的重要任务。 원시 데이터는 노이즈가 많고, 불안정하고, 값이 누락된 경우가 종종 있습니다. 이러한 데이터를 모델링에 사용하면 결과가 잘못될 수 있습니다. 이러한 작업은 TDSP(팀 데이터 과학 프로세스)의 일부이며 일반적으로 필요한 전처리를 검색하고 계획하는 데 사용되는 데이터 세트의 초기 탐색을 수행합니다. TDSP 프로세스에 대한 자세한 지침은 [팀 데이터 과학 프로세스](overview.md)에 설명된 단계를 참조하세요.

预处理和清理任务（如数据浏览任务）可以在各种环境（如 SQL 或 Hive 或 Azure 机器学习 Studio （经典））中执行，也可以使用各种工具和语言（如 R 或 Python），这取决于您的数据的存储和格式化方式。 TDSP는 반복 성향을 띠기 때문에, 이러한 작업은 프로세스의 워크플로 내의 다양한 단계에서 발생할 수 있습니다.

本文介绍可在将数据引入到 Azure 机器学习 Studio （经典）之前或之后执行的各种数据处理概念和任务。

有关 Azure 机器学习 Studio （经典）中的数据浏览和预处理完成的示例，请参阅[预处理数据](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/)视频。

## <a name="why-pre-process-and-clean-data"></a>데이터 전처리 및 정리가 필요한 이유
실제 데이터는 다양한 소스 및 프로세스에서 수집되며 데이터 세트의 품질을 떨어트리는 이상값 또는 손상된 값이 포함될 수 있습니다. 다음과 같은 일반적인 데이터 품질 문제가 자주 발생합니다.

* **불완전**: 데이터에 특성이 없거나 값이 누락되었습니다.
* **노이즈가 많은**: 데이터에 잘못된 레코드 또는 이상값이 있습니다.
* **불일치**: 데이터에 충돌하는 레코드 또는 일치하지 않는 값이 있습니다.

우수한 예측 모델을 구축하려면 우수한 데이터가 필요합니다. "쓰레기를 넣고 쓰레기를 얻는 현상"을 방지하고 데이터 품질을 높여서 궁극적으로 모델 성능을 높이려면 데이터 상태 검사를 수행하여 조기에 데이터 문제를 발견하고 적절한 데이터 처리 및 정리 단계를 결정하는 것이 중요합니다.

## <a name="what-are-some-typical-data-health-screens-that-are-employed"></a>가장 일반적으로 사용되는 데이터 상태 검사 방법으로 어떤 것이 있습니까?
다음을 검사하여 데이터의 전체적인 품질을 확인할 수 있습니다.

* **레코드**수.
* **특성**(또는 **기능**) 수.
* 특성 **데이터 유형** (명목, 서수 또는 연속).
* **누락된 값**의 수.
* **格式正确的**数据。
  * 데이터가 TSV 또는 CSV로 되어 있으면 열 구분 기호 및 줄 구분 기호가 열과 줄을 항상 올바르게 구분하는지 확인합니다.
  * 데이터가 HTML 또는 XML 형식이면 해당 표준에 따라 올바르게 구성되었는지 확인합니다.
  * 또한 반 구조적 데이터 또는 구조화되지 않은 데이터에서 구조적 정보를 추출하려면 구문 분석이 필요할 수 있습니다.
* **일관되지 않은 데이터 레코드**. 값의 범위가 허용되는지 확인하세요. 例如，如果数据包含学生 GPA （年级平均评分），请检查 GPA 是否在指定的范围内，比如 0 ~ 4。

如果发现数据存在问题，则需要**处理步骤**，这通常涉及清理缺失值、数据规范化、离散化、用于删除和/或替换嵌入字符的文本处理（可能会影响数据的对齐方式）、混合数据类型和公共字段等。

**Azure Machine Learning에서는 올바르게 구성된 테이블 형식 데이터를 사용합니다**.  如果数据已经是表格形式，则可以直接在机器学习中 Azure 机器学习 Studio （经典）执行数据预处理。  데이터가 테이블 형식이 아닌 XML 형식이라고 한다면 데이터를 테이블 형식으로 변환하려면 구분 분석이 필요할 수 있습니다.  

## <a name="what-are-some-of-the-major-tasks-in-data-pre-processing"></a>데이터 전처리의 주요 작업
* **数据清理**：填充缺失值，检测并删除干扰性数据和离群值。
* **데이터 변환**: 데이터를 정규화하여 차원 및 노이즈를 줄입니다.
* **데이터 감소**: 데이터를 쉽게 처리할 수 있도록 데이터 레코드 또는 특성을 샘플링합니다.
* **데이터 분할**: 특정 Machine Learning 방법에 쉽게 사용할 수 있도록 연속 특성을 범주 특성으로 변환합니다.
* **文本清除**：删除可能导致数据不一致的嵌入字符，例如，以制表符分隔的数据文件中的嵌入选项卡，例如，可能会破坏记录的嵌入的新行。

아래 섹션에서는 일부 데이터 처리 단계에 대해 자세히 설명합니다.

## <a name="how-to-deal-with-missing-values"></a>누락된 값을 처리하는 방법
누락된 값을 처리하려면 누락된 값이 문제 해결에 더 나은 이유를 먼저 확인하는 것이 좋습니다. 일반적인 누락 값 처리 방법은 다음과 같습니다.

* **삭제**: 값이 누락된 레코드를 제거합니다.
* **더미 대체**: 누락된 값을 더미로 대체합니다. 예를 들어 범주 값은 *알 수 없음*, 숫자 값은 0으로 대체합니다.
* **평균 대체**: 누락된 값이 숫자이면 평균으로 대체합니다.
* **빈도 대체**: 누락된 값이 범주이면 가장 빈도가 높은 항목으로 대체합니다.
* **회귀 대체**: 회귀 메서드를 사용하여 누락된 값을 회귀된 값으로 대체합니다.  

## <a name="how-to-normalize-data"></a>데이터를 정규화하는 방법
数据规范化将数值重新缩放指定范围。 일반적인 데이터 정규화 방법은 다음과 같습니다.

* **최소-최대 정규화**: 0과 1 사이에서 데이터를 선형적으로 범위로 변환합니다. 여기서 최소값은 0, 최대값은 1로 조정됩니다.
* **Z 점수 정규화**: 평균 및 표준 편차를 기반으로 데이터 조정: 데이터와 평균의 차이를 표준 편차로 나눕니다.
* **소수점 배열**: 특성 값의 소수점을 이동하여 데이터 크기를 조정합니다.  

## <a name="how-to-discretize-data"></a>데이터를 분할하는 방법
연속 값을 명목 특성 또는 간격으로 변환하여 데이터를 분할할 수 있습니다. 다음은 이 작업을 수행하는 방법 중 일부입니다.

* **동일 너비 범주화**: 특성의 모든 가능한 값 범위를 크기가 같은 N개의 그룹으로 나누고 bin 번호를 사용하여 bin에 속하는 값을 할당합니다.
* **동일 높이 범주화**: 특성의 모든 가능한 값 범위를 인스턴스 수가 같은 N개의 그룹으로 나누고 bin 번호를 사용하여 bin에 속하는 값을 할당합니다.  

## <a name="how-to-reduce-data"></a>데이터를 줄이는 방법
데이터를 쉽게 처리할 수 있도록 데이터 크기를 줄이는 다양한 방법이 있습니다. 데이터 크기 및 도메인에 따라 다음 방법을 적용할 수 있습니다.

* **레코드 샘플링**: 데이터 레코드를 샘플링하고 데이터에서 대표적인 하위 집합만 선택합니다.
* **특성 샘플링**: 데이터에서 가장 중요한 특성의 하위 집합만 선택합니다.  
* **집계**: 데이터를 여러 그룹으로 나누고 각 그룹에 대한 숫자를 저장 합니다. 예를 들어 어떤 식당 체인의 지난 20년 간 일일 수익을 월별 수익으로 집계하면 데이터 크기를 줄일 수 있습니다.  

## <a name="how-to-clean-text-data"></a>텍스트 데이터를 정리하는 방법
**表格数据中的文本字段**可能包含影响列对齐和/或记录边界的字符。 例如，制表符分隔文件中的嵌入选项卡会导致列不一致，并且嵌入的新行字符会破坏记录行。 写入或读取文本时，不正确的文本编码处理会导致信息丢失、无意中引入了不可读字符（如 null），并且还可能会影响文本分析。 데이터를 올바르게 정렬하고 구조화되지 않은 데이터 또는 반 구조적 데이터에서 구조적 데이터를 추출할 수 있도록 텍스트 필드를 정리하려면 신중한 구문 분석 및 편집 작업이 필요할 수 있습니다.

**데이터 탐색**을 통해 초기에 데이터를 살펴볼 수 있습니다. 이 단계에서 다양한 데이터 문제를 파악하고 그에 맞는 적절한 방법을 적용하여 이러한 문제를 해결할 수 있습니다.  문제의 원인이 무엇인지, 문제가 어떻게 시작되었는지 등의 질문에 대한 답을 고민해 보는 것이 중요합니다. 此过程还可帮助您决定需要执行哪些数据处理步骤来解决这些问题。 确定最终用例和角色还可用于确定数据处理工作量的优先级。

## <a name="references"></a>참조
> *데이터 마이닝: 개념 및 기술*, Third Edition, Morgan Kaufmann, 2011, Jiawei Han, Micheline Kamber 및 Jian Pei
> 
> 

