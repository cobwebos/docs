---
title: 映射数据流中的源转换-Azure 数据工厂 |Microsoft Docs
description: 了解如何在映射数据流中设置源转换。
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 09/06/2019
ms.openlocfilehash: c7d18ab6e9018511915e9b77ea02ac60b1277c12
ms.sourcegitcommit: b4f201a633775fee96c7e13e176946f6e0e5dd85
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 10/18/2019
ms.locfileid: "72596495"
---
# <a name="source-transformation-for-mapping-data-flow"></a>映射数据流的源转换 



源转换为数据流配置数据源。 在设计数据流时，第一步将始终配置源转换。 若要添加源，请在数据流画布中单击 "**添加源**" 框。

每个数据流需要至少一个源转换，但你可以根据需要添加任意多个源来完成数据转换。 您可以将这些源与联接、查找或联合转换一起联接。

每个源转换只与一个数据工厂数据集相关联。 数据集定义要写入或读取的数据的形状和位置。 如果使用基于文件的数据集，则可以使用源中的通配符和文件列表一次处理多个文件。

## <a name="supported-connectors-in-mapping-data-flow"></a>映射数据流中支持的连接器

映射数据流遵循提取、加载和转换（ELT）方法，并且适用于所有 Azure 中的*临时*数据集。 当前，以下数据集可用于源转换：
    
* Azure Blob 存储
* Azure Data Lake Storage Gen1
* Azure Data Lake Storage Gen2
* Azure SQL 数据仓库
* Azure SQL Database

Azure 数据工厂可访问超过80个本机连接器。 若要在数据流中包含其他源中的数据，请使用复制活动将该数据加载到某个支持的暂存区域。

## <a name="source-settings"></a>源设置

添加源后，请通过 "**源设置**" 选项卡进行配置。可在此处选取或创建源指向的数据集。 还可以选择数据的架构和采样选项。

![源设置选项卡](media/data-flow/source1.png "源设置选项卡")

**架构偏差：** [架构偏差](concepts-data-flow-schema-drift.md)是指数据工厂本机处理数据流中的灵活架构的能力，无需显式定义列更改。

* 如果源列经常更改，请选中 "**允许架构偏差**" 框。 此设置允许所有传入的源字段流过到接收器的转换。

* 选择 "**推断偏移列类型**" 会指示数据工厂检测并定义发现的每个新列的数据类型。 关闭此功能后，所有偏移列都将为字符串类型。

**验证架构：** 如果选择了 "验证架构"，则当传入的源数据与数据集的已定义架构不匹配时，数据流将无法运行。

**跳过行计数：** "跳过行计数" 字段指定在数据集的开头要忽略多少行。

**采样：** 启用采样以限制源中的行数。 当你在源中测试数据或对数据进行采样以便进行调试时，请使用此设置。

**多行行：** 如果源文本文件包含跨多行的字符串值（即值中的换行符），请选择多行行。

若要验证是否正确配置了源，请打开调试模式并提取数据预览。 有关详细信息，请参阅[调试模式](concepts-data-flow-debug-mode.md)。

> [!NOTE]
> 当调试模式处于打开状态时，"调试" 设置中的行限制配置将覆盖数据预览期间源中的采样设置。

## <a name="file-based-source-options"></a>基于文件的源选项

如果你使用的是基于文件的数据集（例如 Azure Blob 存储或 Azure Data Lake Storage），则 "**源选项**" 选项卡可让你管理源读取文件的方式。

![源选项](media/data-flow/sourceOPtions1.png "源选项")

**通配符路径：** 使用通配符模式将指示 ADF 通过单个源转换循环遍历每个匹配的文件夹和文件。 这是在单个流中处理多个文件的有效方法。 添加多个通配符匹配模式，并在将鼠标悬停在现有通配符模式上时显示的 + 符号。

从源容器中，选择与模式匹配的一系列文件。 只能在数据集中指定容器。 因此，你的通配符路径必须包含根文件夹中的文件夹路径。

通配符示例：

* ```*``` 表示任意字符集
* ```**``` 表示递归目录嵌套
* ```?``` 替换一个字符
* ```[]``` 匹配括号中的一个或多个字符

* ```/data/sales/**/*.csv``` 获取/data/sales 下的所有 csv 文件。
* ```/data/sales/20??/**``` 获取20世纪的所有文件
* ```/data/sales/2004/*/12/[XY]1?.csv``` 获取2004年12月开始的所有 csv 文件，以两位数作为前缀的 X 或 Y

**分区根路径：** 如果文件源中的分区文件夹采用 ```key=value``` 格式（例如，year = 2019），则可以将该分区文件夹树的顶层分配给数据流数据流中的列名称。

首先，设置一个通配符，以包括所有作为分区文件夹的路径，以及要读取的叶文件。

![分区源文件设置](media/data-flow/partfile2.png "分区文件设置")

使用 "分区根路径" 设置来定义文件夹结构的顶层。 通过数据预览查看数据的内容时，会看到 ADF 会添加在每个文件夹级别中找到的已解析分区。

![分区根路径](media/data-flow/partfile1.png "分区根路径预览")

**文件列表：** 这是一个文件集。 创建一个文本文件，其中包含要处理的相对路径文件的列表。 指向此文本文件。

**要存储文件名的列：** 将源文件的名称存储在数据中的列中。 在此处输入新的列名来存储文件名字符串。

**完成后：** 选择在数据流运行后对源文件执行任何操作、删除源文件或移动源文件。 移动的路径是相对路径。

若要将源文件移到其他位置，请先选择 "移动" 进行文件操作。 然后，设置 "从" 目录。 如果没有为路径使用任何通配符，则 "源" 设置将是与源文件夹相同的文件夹。

如果源路径带有通配符，则语法如下所示：

```/data/sales/20??/**/*.csv```

你可以指定 "from" 作为

```/data/sales```

和 "to" as

```/backup/priorSales```

在这种情况下，/data/sales 下的所有文件都将移动到/backup/priorSales。

> [!NOTE]
> 仅当您从管道运行（管道调试或执行运行）中的数据流开始使用管道中的 "执行数据流" 活动时，才运行文件操作。 文件操作*不会*在数据流调试模式下运行。

**按上次修改时间筛选：** 您可以通过指定上次修改的日期范围来筛选处理的文件。 所有日期时间都采用 UTC 格式。 

### <a name="add-dynamic-content"></a>添加动态内容

所有源设置都可以使用[映射数据流的转换表达式语言](data-flow-expression-functions.md)指定为表达式。 若要添加动态内容，请在 "设置" 面板中的字段内单击或悬停。 单击 "**添加动态内容**" 的超链接。 这将启动表达式生成器，可在其中使用表达式、静态文本值或参数动态设置值。

![参数](media/data-flow/params6.png "parameters")

## <a name="sql-source-options"></a>SQL 源选项

如果源在 SQL 数据库或 SQL 数据仓库中，则 "**源选项**" 选项卡中还提供了其他特定于 SQL 的设置。 

**输入：** 选择是将源指向某个表（等效于 ```Select * from <table-name>```）还是输入自定义 SQL 查询。

**查询**：如果在输入字段中选择 "查询"，则输入源的 SQL 查询。 此设置将重写您在数据集中选择的任何表。 此处不支持**Order By**子句，但你可以设置完整的 SELECT FROM 语句。 你还可以使用用户定义的表函数。 **select * From udfGetData （）** 是返回表的 SQL 中的 UDF。 此查询将生成可以在数据流中使用的源表。

**批大小**：输入用于将大型数据拆分为读取的批大小。

**隔离级别**：映射数据流中 SQL 源的默认值为 "未提交读"。 可以将此处的隔离级别更改为以下值之一：
* 已提交读
* 未提交读
* 可重复的读取
* 序列
* 无（忽略隔离级别）

![隔离级别](media/data-flow/isolationlevel.png "隔离级别")

## <a name="projection"></a>投影

与数据集中的架构一样，源中的投影定义源数据中的数据列、类型和格式。 对于大多数数据集类型（例如 SQL 和 Parquet），源中的投影是固定的，以反映数据集中定义的架构。 如果源文件不是强类型的（例如，平面 csv 文件而不是 Parquet 文件），则可以定义源转换中每个字段的数据类型。

!["投影" 选项卡上的设置](media/data-flow/source3.png "投影")

如果文本文件没有定义的架构，请选择 "**检测数据类型**"，以便数据工厂将采样并推断数据类型。 选择 "**定义默认格式**" 以自动检测默认数据格式。 

可以在流下派生列转换中修改列数据类型。 使用 select 转换来修改列名称。

## <a name="optimize-the-source-transformation"></a>优化源转换

在源转换的 "**优化**" 选项卡上，可能会看到**源**分区类型。 仅当你的源是 Azure SQL 数据库时，此选项才可用。 这是因为数据工厂会尝试建立并行连接，以针对 SQL 数据库源运行大型查询。

![源分区设置](media/data-flow/sourcepart3.png "partitioning")

不需要对 SQL 数据库源上的数据进行分区，但分区对于大型查询很有用。 您可以将分区基于列或查询。

### <a name="use-a-column-to-partition-data"></a>使用列对数据进行分区

从源表中，选择要进行分区的列。 同时设置分区数。

### <a name="use-a-query-to-partition-data"></a>使用查询对数据进行分区

您可以选择基于查询对连接进行分区。 输入 WHERE 谓词的内容。 例如，输入 year > 1980。

有关映射数据流中的优化的详细信息，请参阅 "[优化" 选项卡](concepts-data-flow-overview.md#optimize)。

## <a name="next-steps"></a>后续步骤

开始生成[派生列转换](data-flow-derived-column.md)和[select 转换](data-flow-select.md)。
