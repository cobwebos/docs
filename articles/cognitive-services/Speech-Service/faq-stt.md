---
title: 有关 Azure 中语音转文本服务的常见问题
titleSuffix: Azure Cognitive Services
description: 获取有关语音转文本服务的最常见问题的解答。
services: cognitive-services
author: PanosPeriorellis
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 06/11/2018
ms.author: panosper
ms.openlocfilehash: 6cc530d2680c0410081ad3ad3e573cd59d5583d6
ms.sourcegitcommit: a12b2c2599134e32a910921861d4805e21320159
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 06/24/2019
ms.locfileid: "67341964"
---
# <a name="speech-to-text-frequently-asked-questions"></a>语音转文本常见问题解答

如果在本常见问题解答中找不到你的问题的解答，请检查[其他支持选项](support.md)。

## <a name="general"></a>常规

**问：基线模型和自定义语音转文本模型之间有什么区别？**

**答**：基线模型已使用 Microsoft 拥有的数据定型，并且已部署在云中。  你可以使用自定义模型来调整模型，以便更好地适应具有特定环境噪音或语言的具体环境。 工厂、汽车或嘈杂的街道需要适应的声学模型。 生物学、物理学、放射学、产品名称和自定义首字母缩略词等主题需要适应的语言模型。

**问：如果想要使用基线模型，从何处开始？**

**答**：首先，获取[订阅密钥](get-started.md)。 如果想要对预先部署的基线模型进行 REST 调用，请参阅 [REST API](rest-apis.md)。 如果想要使用 WebSocket，请[下载 SDK](speech-sdk.md)。

**问：是否始终需要生成自定义语音模型？**

**答**：不是。 如果应用程序使用通用的日常语言，则无需自定义模型。 如果应用程序用于背景噪音很小或无背景噪音的环境，则无需自定义模型。

你可以在门户中部署基线模型和自定义模型，并针对这些模型运行准确度测试。 可以使用此功能衡量基线模型与自定义模型的准确度。

**问：如何知道何时完成数据集或模型的处理？**

**答**：目前，表中模型或数据集的状态是唯一可以了解的途径。 处理完成后，状态是“成功”  。

**问：能否创建多个模型？**

**答**：集合中可以拥有的模型数量没有限制。

**问：我意识到自己犯了一个错误。** 如何取消正在进行的数据导入或模型创建？

**答**：当前无法回滚声学或语言适应过程。 可以在导入的数据和模型处于终点状态时删除它们。

**问：搜索和听写模型与对话模型之间有什么区别？**

**答**：你可以在语音服务中从多个基线模型中进行选择。 对话模型适用于识别以对话方式说出的语音。 此模型非常适合转录电话。 搜索和听写模型非常适合语音触发的应用。 通用模型是一种旨在解决这两种情况的新模型。 在大多数区域设置中，通用模型目前处于或高于对话式模型的质量级别。

**问：能否更新现有模型（模型堆叠）？**

**答**：无法更新现有模型。 一种解决方案是将旧数据集与新数据集合并，然后重新适应。

旧数据集和新数据集必须合并为单个 .zip 文件（用于声学数据）或 .txt 文件（用于语言数据）。 适应完成后，需要重新部署新的更新后模型以获取新的终结点

**问：当新版本的基线可用时，是否会自动更新我的部署？**

**答**：部署不会自动更新。

如果已调整并部署了具有基线 V1.0 的模型，该部署将保持原样。 客户可以解除已部署的模型，使用较新版本的基线重新调整并重新部署。

**问：如果我的已部署模型需要比门户提供的并发性更高的并发性，该怎么办？**

**答**：以 20 个并发请求为增量纵向扩展模型。

请联系[语音支持](mailto:speechsupport@microsoft.com?subject=Request%20for%20higher%20concurrency%20for%20Speech-to-text)如果需要更高的规模。

**问：能否下载模型并在本地运行？**

**答**：无法下载模型并在本地执行。

**问：是否会记录我的请求？**

**答**：在创建部署时你可以选择关闭跟踪。 此时，不会记录任何音频或听录。 否则，通常会将请求以安全存储方式记录在 Azure 中。

**问：我的请求是否受到限制？**

**答**：REST API 将请求限制为每 5 秒 25 个。 可以在我们的[语音转文本](speech-to-text.md)页面中找到详细信息。

如果有禁止使用自定义语音服务的其他隐私问题，请联系其中一个支持渠道。

## <a name="importing-data"></a>导入数据

**问：数据集大小的限制是什么？为何限制？**

**答**：答：数据集的当前限制为 2 GB。 之所以有此限制，是由于 HTTP 上传文件大小存在限制。 

**问：是否可以压缩文本文件，以便上传更大的文本文件？** 

**答**：不是。 目前，仅允许未压缩的文本文件。

**问：数据报告表明，有言语导入失败。问题出在哪里？**

**答**：未能上传文件中 100% 的话语并不是什么问题。 如果成功导入了声学或语言数据集中的绝大多数话语（如 95% 以上的话语），则该数据集可用。 但是，建议尝试了解话语失败的原因并解决问题。 大多数常见问题（如格式设置错误）很容易修复。 

## <a name="creating-an-acoustic-model"></a>创建声学模型

**问：需要多少声学数据？**

**答**：建议开始时先使用 30 分钟到 1 小时的声学数据。

**问：应该收集哪些数据？**

**答**：收集尽可能接近于应用程序方案和用例的数据。 数据收集应在设备、环境和说话人类型方面与目标应用程序和用户匹配。 一般而言，应从尽可能广泛的说话人中收集数据。 

**问：如何收集声学数据？**

**答**：可以创建独立的数据收集应用程序，或使用现成的录音软件。 你还可以创建一个用于记录音频数据并使用该数据的应用程序版本。 

**问：是否需要自行转录适应数据？**

**答**： 能！ 可以自行转录或使用专业听录服务进行转录。 有些用户更喜欢使用专业听录器，而其他用户则使用众包或自己进行听录。

## <a name="accuracy-testing"></a>精确度测试

**问：是否可以使用自定义语言模型对我的自定义声学模型执行离线测试？**

**答**：可以，只需在设置离线测试时从下拉菜单中选择自定义语言模型即可。

**问：是否可以使用自定义声学模型对我的自定义语言模型执行离线测试？**

**答**：可以，只需在设置脱机测试时，选择下拉菜单中的自定义声学模型即可。

**问：什么是字错误率 (WER) 以及如何计算此错误率？**

**答**：WER 是用于语音识别的评估指标。 WER 由错误总数（包括插入、删除和替换）除以引用听录中的总字数得出。 有关详细信息，请参阅[字错误率](https://en.wikipedia.org/wiki/Word_error_rate)。

**问：如何确定准确度测试的结果是否良好？**

**答**：测试结果对基线模型和自定义模型进行了比较。 应以超越基线模型为目标，使自定义模型变得有价值。

**问：如何确定基础模型的 WER 以便查看是否有改进？** 

**答**：离线测试结果显示了自定义模型的基线准确度以及与基线相比的改进情况。

## <a name="creating-a-language-model"></a>创建语言模型

**问：需要上传多少文本数据？**

**答**：这取决于应用程序中使用的词汇和短语与初始语言模型存在多大差异。 对于所有新字词，尽可能多地提供这些字的使用示例很有用。 对于应用程序中使用的常用短语，在语言数据中添加短语也很有用，因为这会告知系统也要侦听这些术语。 在语言数据集中至少有 100 句话语（通常几百句或更多话语）是很常见的。 另外，如果预期某些类型的查询比其他查询更加常用，则可以在数据集中插入常用查询的多个副本。

**问：能否只上传字词列表？**

**答**：上传字词列表会将字词添加到词汇中，但不会告知系统这些字词的通常用法。 通过提供完整或部分话语（用户很可能会说事物的句子或短语），语言模型可以学习这些新字词及其用法。 自定义语言模型不仅适用于向系统中添加新字词，还适用于调整应用程序已知字词的概率。 提供完整话语可帮助系统更好地学习。 

## <a name="next-steps"></a>后续步骤

* [故障排除](troubleshooting.md)
* [发行说明](releasenotes.md)
